{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from utils import adversarial_samples\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import os \n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from modified_stable_diffusion import ModifiedStableDiffusionPipeline\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image,ImageFilter,ImageEnhance\n",
    "import PIL \n",
    "from encoder_decoder_pretrain.watermark_model import *\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='diffusion watermark')\n",
    "    parser.add_argument('--w_seed', default=0, type=int)\n",
    "    parser.add_argument('--dataset', default='Gustavosta/Stable-Diffusion-Prompts')\n",
    "    # parser.add_argument('--model_path', default='../stable-diffusion-2-1-base')\n",
    "    parser.add_argument('--model_path', default='../stable-diffusion-v1-4')\n",
    "    parser.add_argument('--image_length', default=512, type=int)\n",
    "    parser.add_argument('--secret_length', default=48, type=int)\n",
    "    parser.add_argument('--num_inference_steps', default=20, type=int)\n",
    "    parser.add_argument('--guidancescale', default=5, type=float)\n",
    "    parser.add_argument('--reverse_inference_steps', default=20, type=int)\n",
    "    parser.add_argument('--batchsize', default=1, type=int)\n",
    "    parser.add_argument('--lr', default=0.0005, type=float)\n",
    "    parser.add_argument('--steps', default=4000, type=int)\n",
    "    parser.add_argument('--checkpoint', default='./model48bit_finetuned.pth', type=str)\n",
    "    parser.add_argument('--save_path', default='./model48bit_finetuned.pth', type=str)\n",
    "    args =parser.parse_known_args()[0]\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    torch.set_printoptions(sci_mode=False,profile='full')\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    maxlength=150\n",
    "    \n",
    "    #Prompt Dataset\n",
    "    dataset, prompt_key = get_dataset(args)\n",
    "    dataset=promptdataset(dataset,prompt_key)\n",
    "\n",
    "    #Load Diffusion Model\n",
    "    scheduler = DPMSolverMultistepScheduler.from_pretrained(args.model_path, subfolder='scheduler')\n",
    "    pipe = ModifiedStableDiffusionPipeline.from_pretrained(\n",
    "            args.model_path,\n",
    "            scheduler=scheduler,\n",
    "            torch_dtype=torch.float16,\n",
    "            revision='fp16',\n",
    "            )\n",
    "    pipe = pipe.to(device)\n",
    "\n",
    "    #Load DiffuseTrace\n",
    "    wm = Watermark(secret_length=args.secret_length).to(device)\n",
    "    if args.checkpoint is not None: \n",
    "        wm.load_state_dict(torch.load(args.checkpoint))\n",
    "        \n",
    "    #freeze the batchnorm layer\n",
    "    wm.eval()\n",
    "    \n",
    "    #generator\n",
    "    # generator = torch.Generator(device=pipe.text_encoder.device)\n",
    "    # generator.manual_seed(0)\n",
    "\n",
    "    #optimizer\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': wm.decoder_projection.parameters()},\n",
    "        {'params': wm.decoder.parameters()},\n",
    "\n",
    "    ], lr=args.lr)\n",
    "    progress_bar1 = tqdm(total=args.steps, desc=f'steps')\n",
    "\n",
    "    for i in range(args.steps):\n",
    "            optimizer.zero_grad()\n",
    "            #secret batch\n",
    "            X=[]\n",
    "            for j in range(args.batchsize):\n",
    "                    binary=torch.Tensor(np.random.choice([0, 1], size=(args.secret_length))).to(device)\n",
    "                    binary = binary.unsqueeze(-1).unsqueeze(-1).unsqueeze(0)\n",
    "                    binary = binary.expand(-1,-1,64,64)\n",
    "                    X.append(binary)\n",
    "            batch=torch.cat(X,dim=0).to(device)\n",
    "            #watermark distribution\n",
    "            _,Mean,Logvar=wm(batch)\n",
    "            mean=Mean.reshape(-1,4,64,64)\n",
    "            logvar=Logvar.reshape(-1,4,64,64)\n",
    "            eps = torch.randn_like(logvar)\n",
    "            std = torch.exp(logvar / 2)\n",
    "            init_latents = eps * std + mean\n",
    "            init_latents=init_latents.half()\n",
    "            reverse_latents=None\n",
    "            \n",
    "            #inference\n",
    "            with torch.no_grad():\n",
    "                prompt=dataset[random.randint(0,len(dataset)-1)][0:maxlength]\n",
    "                print(prompt)\n",
    "                img= pipe(prompt=prompt,num_inference_steps=args.num_inference_steps,\\\n",
    "                latents=init_latents,guidance_scale=args.guidancescale,num_images_per_prompt=len(batch)).images\n",
    "\n",
    "            #adversarial samples\n",
    "            img,batch=adversarial_samples(img,batch,device,X,args)\n",
    "                        \n",
    "            #reverseï¼š\n",
    "            reverse_latents_list=[]\n",
    "            for r in range(len(img)):\n",
    "                latents=reverse(img[r],pipe,args).unsqueeze(0)\n",
    "                reverse_latents_list.append(latents)\n",
    "            reverse_latents = torch.cat(tuple(reverse_latents_list), dim=0).float()\n",
    "            reverse_latents = reverse_latents.view(len(img), -1)  \n",
    "            \n",
    "            #decode                                                                                                                                    \n",
    "            x = wm.decoder_projection(reverse_latents)\n",
    "            x = torch.reshape(x, (-1, *wm.decoder_input_chw))\n",
    "            \n",
    "            #calculate loss\n",
    "            recloss=F.mse_loss(batch,wm.decoder(x),reduction='sum')\n",
    "            original_secret = torch.mean(batch, dim=(-2, -1))\n",
    "            pred_secret = torch.round(torch.mean(wm.decoder(x), dim=(-2, -1)))\n",
    "            pred_secret_tensor = torch.mean(wm.decoder(x)[0], dim=(-2, -1))\n",
    "            loss=recloss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #loss\n",
    "            print(f'max loss bits={(torch.sum(abs(original_secret-pred_secret),dim=1))}')\n",
    "            print(f'max loss bits={torch.max(torch.sum(abs(original_secret-pred_secret),dim=1))}')\n",
    "            \n",
    "            #process bar update\n",
    "            progress_bar1.set_postfix(steps=f'{i}', recloss=f'{loss:.4f}')\n",
    "            progress_bar1.update(1)\n",
    "            \n",
    "            if i%10==0 and i>1:\n",
    "                torch.save(wm.state_dict(),'model48bit_finetuned.pth')\n",
    "    #save model\n",
    "    torch.save(wm.state_dict(),'model48bit_finetuned.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
